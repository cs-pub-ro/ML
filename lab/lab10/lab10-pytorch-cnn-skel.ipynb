{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab10/lab10-pytorch-cnn-skel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xi1dtiTtK1Ov"
   },
   "source": [
    "Lab 10 : Rețele Convoluționale în PyTorch\n",
    "===================================\n",
    "\n",
    "### Clasificare supervizată folosind arhitectura ResNet-50\n",
    "\n",
    "Exemple introduse în acest laborator:\n",
    "- preprocesarea datelor în PyTorch ([data transforms](https://pytorch.org/docs/stable/torchvision/transforms.html))\n",
    "- utilizarea unui [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "- definirea unei arhitecturi convoluționale în PyTorch\n",
    "- efectul utilizării normalizării la nivel de batch (batch normalization - [Descriere](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c), [Modul PyTorch](https://pytorch.org/docs/stable/nn.html#batchnorm2d)) în arhitecturi convoluționale adânci\n",
    "- ciclul de antrenare al unei rețele în PyTorch\n",
    "\n",
    "\n",
    "**Credit**:\n",
    "- Exercitii și structură cod adaptate din tutorialul ConvNet al Vioricăi Pătrăucean, din cadrul EEML 2019.\n",
    "- Arhitectura ResNet-50 din PyTorch model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Ho_PioVRL_o",
    "outputId": "3e817e11-6142-44e0-98e9-c1f9777e016b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definirea mediului pe care va rula codul de antrenare\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'Running code @ {device}')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library.\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "import collections\n",
    "import enum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmjogSWJ-Xlt"
   },
   "source": [
    "## Descărcare și preparare date\n",
    "\n",
    "* **Cifar-10** este echivalentul MNIST pentru imagini naturale RGB\n",
    "\n",
    "* cuprinde 60k 32x32 imagini color din 10 clase: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\n",
    "* train: 50k; test: 10k\n",
    "\n",
    "\n",
    "**Exemplu 1: Implementarea unor metode de augmentare de date**\n",
    "\n",
    "În Pytorch pot fi folosite _transformări de date_ la momentul încărcării în memorie a unui set de date. \n",
    "Pentru aceasta se pot utiliza clase predefinite (din pachetul `torchvision.transforms`) sau pot fi construite clase custom.\n",
    "\n",
    "În acest exemplu folosim _transforms_ pentru a aplica două tehnici de **augmentare a datelor**, folosite la antrenare: oglindiri aleatoare a imaginilor și crop-uri aleatoare ale imaginii (sunt folosite clase existente în pachetul `torchvision.transforms`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "LEEkhc5KRa8t",
    "outputId": "cf7c5d63-c851-4cc3-b00a-dacc790ffc70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare data \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "\n",
    "TRAIN_DATASET_SIZE = 50000\n",
    "TEST_DATASET_SIZE = 10000\n",
    "\n",
    "CIFAR10_IMG_WIDTH = 32\n",
    "CIFAR10_IMG_HEIGHT = 32\n",
    "\n",
    "DATA_MEAN = (0.5, 0.5, 0.5)    # define the mean for the scaling transform - PIL images already come given in \n",
    "DATA_STD = (0.5, 0.5, 0.5)        # define the standard deviation for the scaling transform\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),     # apply random horizontal flip\n",
    "        transforms.RandomCrop(                          # apply random crop, after padding image with 4 values on each side, using `reflect` mode\n",
    "            size=(CIFAR10_IMG_WIDTH, CIFAR10_IMG_HEIGHT), \n",
    "            padding=(4, 4), \n",
    "            padding_mode=\"reflect\"),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DATA_MEAN, DATA_STD)       # normalize the image tensor to [-1, 1] on each channel: img_norm = (img - data_mean) / data_std \n",
    "    ] \n",
    ")\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),                          # on test set we only need to apply the same normalization\n",
    "        transforms.Normalize(DATA_MEAN, DATA_STD) \n",
    "    ] \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_images = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                            transform=train_transform)\n",
    "\n",
    "test_images = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "                                           transform=test_transform)\n",
    "\n",
    "# Check sizes of tensors\n",
    "print(f'Size of training images {train_images.data.shape}')\n",
    "print(f'Size of training labels {len(train_images.targets)}')\n",
    "print(f'Size of test images {test_images.data.shape}')\n",
    "print(f'Size of test labels {len(test_images.targets)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vMPjp0UU4Mx"
   },
   "source": [
    "## Afișare imagini\n",
    "Implementarea unei „galerii” de imagini pentru vizualizarea setului de date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xy0BWFwFUQ0J"
   },
   "outputs": [],
   "source": [
    "MAX_IMAGES = 10\n",
    "\n",
    "def gallery(images, label, title='Input images'):\n",
    "    class_dict = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    num_frames, h, w, num_channels = images.shape\n",
    "    num_frames = min(num_frames, MAX_IMAGES)\n",
    "    ff, axes = plt.subplots(1, num_frames, figsize=(num_frames, 1), subplot_kw={'xticks': [], \n",
    "                                                                                'yticks': []})\n",
    "    for i in range(0, num_frames):\n",
    "        if num_channels == 3:\n",
    "            axes[i].imshow(np.squeeze(images[i]))\n",
    "        else:\n",
    "            axes[i].imshow(np.squeeze(images[i]), cmap='gray')\n",
    "        axes[i].set_title(class_dict[label[i]])\n",
    "        plt.setp(axes[i].get_xticklabels(), visible=False)\n",
    "        plt.setp(axes[i].get_yticklabels(), visible=False)\n",
    "    ff.subplots_adjust(wspace=0.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWvJh11N-rYX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "7kGaRa23RfjT",
    "outputId": "93c17195-d219-4398-9859-689594a9a604"
   },
   "outputs": [],
   "source": [
    "gallery(train_images.data, train_images.targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pgKO2uEU_tn"
   },
   "source": [
    "## Pregătirea datelor pentru antrenare și testare\n",
    "* pentru antrenare folosim optimizatori stocastici (e.g. SGD, Adam), asa că trebuie sa putem eșantiona exemple aleatoare din setul de date pentru a forma mini-batch-uri\n",
    "* pentru testare iterăm în mod secvențial prin setul de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "a7DbXWyoRjO6",
    "outputId": "c41ff867-0428-415b-dbc0-e13c7d7abe54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: torch.Size([100, 3, 32, 32])\n",
      "Shape of training labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# define dimension of the batches to sample from the datasets\n",
    "BATCH_SIZE_TRAIN = 100  #@param\n",
    "BATCH_SIZE_TEST = 100  #@param\n",
    "NO_WORKERS = 8  #@param\n",
    "SHUFFLE_DATA = True\n",
    "\n",
    "# create Dataset iterator object using the data previously downloaded\n",
    "# we shuffle the data and sample repeatedly batches for training\n",
    "train_loader = torch.utils.data.DataLoader(train_images, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                           shuffle=SHUFFLE_DATA, \n",
    "                                           num_workers=NO_WORKERS)\n",
    "\n",
    "# get a training batch of images and labels\n",
    "(batch_train_images, batch_train_labels) = next(iter(train_loader))\n",
    "\n",
    "# check that the shape of the training batches is the expected one\n",
    "print(f'Shape of training images: {batch_train_images.size()}')\n",
    "print(f'Shape of training labels: {batch_train_labels.size()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gpHYjHEiRmvs",
    "outputId": "39b420e6-e76b-4383-f599-fddf7da0e985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test images: torch.Size([100, 3, 32, 32])\n",
      "Shape of test labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# we do the same for test dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_images, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                          shuffle=SHUFFLE_DATA, \n",
    "                                          num_workers=NO_WORKERS)\n",
    "\n",
    "def loopy_test_loader(dl):\n",
    "    data_iter = iter(dl)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            yield next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(dl)\n",
    "            yield next(data_iter)\n",
    "\n",
    "(batch_test_images, batch_test_labels) = next(iter(test_loader))\n",
    "print(f'Shape of test images: {batch_test_images.size()}')\n",
    "print(f'Shape of test labels: {batch_test_labels.size()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Q9xIZOJEiiU"
   },
   "source": [
    "### Setări generale: nume model, utilizare batch normalization, utilizare regularizare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b8dDvmpEgwM"
   },
   "outputs": [],
   "source": [
    "model = \"resnet_v2\" \n",
    "flag_batch_norm = 'ON'  # @param['ON', 'OFF']\n",
    "flag_regularize = True     # @param['True', 'False'] {type:\"raw\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KA8hnT4H-XmK"
   },
   "source": [
    "## 1. Definirea arhitecturii RESNET-50 - blocuri funcționale\n",
    "\n",
    "Implementarea propusă în PyTorch pentru ResNet-50 definește 4 straturi logice de grupuri _ResNet blocks_. Ele sunt definite în funcție de numărul de canale ce rezultă din fiecare strat logic.\n",
    "\n",
    "Astfel, rețeaua este compusă din urmatoarele blocuri funcționale:\n",
    "  * 3 blocuri ResNet cu 64 canale și  _\"first-block-dimension-reduction-stride\"_ = 1\n",
    "  * 4 blocuri ResNet cu 128 canale și _\"first-block-dimension-reduction-stride\"_ = 2 (i.e. îmjumătățim dimensiunea inputului)\n",
    "  * 6 blocuri ResNet cu 256 canale și _\"first-block-dimension-reduction-stride\"_ = 2 (i.e. îmjumătățim dimensiunea inputului)\n",
    "  * 3 blocuri ResNet cu 512 canale și _\"first-block-dimension-reduction-stride\"_ = 2 (i.e. îmjumătățim dimensiunea inputului)\n",
    "\n",
    "**Observație**: Pentru ca rețeaua ResNet are mulți parametrii, este posibil ca antrenarea ei să dureze mult pe resurse CPU sau chiar Colab.\n",
    "Pentru a înlesni antrenarea, utilizăm un factor de reducere a numărului de canale (`DOWNSIZE_FACTOR`) care împarte numărul de canale rezultant după fiecare strat logic (e.g. 64/4, 128/4, 256/4, 512/4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRsh0ZUeV6m2"
   },
   "outputs": [],
   "source": [
    "# define parameters of resnet blocks for resnet-50 model\n",
    "import collections\n",
    "\n",
    "ResNetBlockParams = collections.namedtuple(\n",
    "    \"ResNetBlockParams\", [\"neck_ch\", \"blocks\", \"stride\"])\n",
    "\n",
    "DOWNSIZE_FACTOR = 4     # @param[8, 4, 2, 1]\n",
    "\n",
    "BLOCKS_50 = (\n",
    "    ResNetBlockParams(int(64/DOWNSIZE_FACTOR), 3, 1),\n",
    "    ResNetBlockParams(int(128/DOWNSIZE_FACTOR), 4, 2),\n",
    "    ResNetBlockParams(int(256/DOWNSIZE_FACTOR), 6, 2),\n",
    "    ResNetBlockParams(int(512/DOWNSIZE_FACTOR), 3, 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEHrKw71-XmO"
   },
   "source": [
    "### TODO 1: definiți apelurile de convoluții 3x3 și 1x1 folosite într-un bloc ResNet-50 \n",
    "Instantiați în mod corespunzător clasa de tip [nn.Conv2d](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) din PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cMC4BWe-XmO"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, padding=1, bias = False):\n",
    "    \"\"\"\n",
    "    3x3 2D convolution with padding=1\n",
    "    @:param in_planes: the number of input channels for the convolution filter\n",
    "    @:param out_planes: the number of output channels for the convolution filter\n",
    "    @:param stride: stride value for the convolution filter, default is 1\n",
    "    @:param padding: the padding to apply, default is 1 to keep width and height the same in the output activation maps \n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO 1.1 return nn.Conv2d(...)\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, bias=False):\n",
    "    \"\"\"\n",
    "    1x1 2D convolution\n",
    "    @:param in_planes: the number of input channels for the convolution filter\n",
    "    @:param out_planes: the number of output channels for the convolution filter\n",
    "    @:param stride: stride value for the convolution filter, default is 1\n",
    "    \"\"\"\n",
    "    # TODO 1.2 return nn.Conv2d(...)\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPF33y9U-XmS"
   },
   "source": [
    "### TODO 2: definiți blocuri ResNet cu \"gâtuire\" (bottleneck)\n",
    "\n",
    "Blocul de tip \"bottleneck\" din ResNet-50 este definit ca în figura următoare.\n",
    "\n",
    "![ResNet-50 Bottleneck block](https://github.com/asorici/NN-labs/blob/master/Lab3-CNN/img/Bottleneck-Blocks-for-ResNet-50-left-identity-shortcut-right-projection-shortcut.png?raw=1)\n",
    "\n",
    "În imaginea din stânga se observă cazul cu `stride=1`, unde blocul nu face o reducere a dimensiunii ( _downsampling_ ) pentru că operația de conv 3x3 efectuată pe partea residuală pastrează dimensiunile (folosind stride=1)\n",
    "\n",
    "Imaginea din dreapta arată operațiile efectuate atunci când `stride=2` și unde ieșirea stratului de gâtuire necesită o operație de _downsampling_ pentru a duce dimensiunea inputului la una egală cu cea înjumătățită care are loc pe calea reziduală.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xby5GIFGaIEh"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 base_width=int(64/DOWNSIZE_FACTOR), norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"\n",
    "        :param inplanes: initial number of input channels for the bottleneck block\n",
    "        :param planes: number of output channels  at the end of the ResNet block\n",
    "        :base_width: the number of channels at the start of the first logical ResNet-50 layer - the default is 64/DOWNSIZE_FACTOR\n",
    "                                  used to derive the channel size `f` of this bottleneck block\n",
    "        :downsample: a 1x1 conv layer that downsamples the input size or `None` if no downsampling needs to be performed \n",
    "        :norm_layer: the type of normalization to apply at after each conv operation, default is nn.BatchNorm2d\n",
    "        \"\"\"\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        # `inplanes` defines the initial number of input channels for the bottleneck block\n",
    "        # `width` encodes the number of filters `f` in the picture of the bottleneck block above \n",
    "        width = int(planes * (base_width / (64./DOWNSIZE_FACTOR)))\n",
    "        \n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        \n",
    "        # BEGIN TODO 2.1\n",
    "        \n",
    "        # first conv 1x1 layer which implements the bottlenecking\n",
    "        # self.conv1 = ...\n",
    "        # self.bn1 = ...\n",
    "        \n",
    "        # conv 3x3 layer which applies the stride given as parameter\n",
    "        # self.conv2 = ...\n",
    "        # self.bn2 = ...\n",
    "        \n",
    "        # conv 1x1 layer where the number of output channels is \"expanded\" according to the defined expansion factor\n",
    "        # according to the above figure, the expansion factor is set to 4\n",
    "        # self.conv3 = ...\n",
    "        # self.bn3 = ...\n",
    "        \n",
    "        # END TODO 2.2\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # TODO 2.2\n",
    "        # first layer conv1 + bn1 + relu\n",
    "        # out = ...\n",
    "        \n",
    "        # second layer conv2 + bn2 + relu\n",
    "        # out = ...\n",
    "        \n",
    "        # third layer conv3 + bn3\n",
    "        # out = ...\n",
    "        \n",
    "        # apply downsample to identity (original input to block), if it is defined (right image in figure above)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        # add identity to residual and apply relu\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s14QG5Et-XmW"
   },
   "source": [
    "## 2. Definirea arhitecturii ResNet-50 - compunerea blocurilor funcționale\n",
    "<div>\n",
    "\t<img title=\"ResNet-50 Architecture\" src=\"https://github.com/asorici/NN-labs/blob/master/Lab3-CNN/img/ResNet-50-arch.jpg?raw=1\" width=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nfiQxXS-XmX"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10, base_width=int(64/DOWNSIZE_FACTOR), \n",
    "                 norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"\n",
    "        Build the ResNet network model - based on PyTorch Model Zoo implementation\n",
    "        \n",
    "        :param block: the Resnet Block model to be used: in our case the `Bottleneck` block\n",
    "        :param layers: the logical layer definition, such as the one in BLOCKS_50\n",
    "        :param num_classes: the number of classes for target labels\n",
    "        :param base_width: the initial number of layers\n",
    "        :param norm_layer: the type of normalization to apply - either BatchNorm or EmptyNorm, default is BatchNorm\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.inplanes = int(64/DOWNSIZE_FACTOR)\n",
    "        self.dilation = 1\n",
    "        self._norm_layer = norm_layer\n",
    "        \n",
    "        self.base_width = base_width\n",
    "        \n",
    "        # ResNet starts out with an initial 7x7 convolution with stride 2 that halves the input size\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)  # image is now 16x16\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # We skip the maxpool layer because it would reduce the size too much starting from a 32 x 32 image \n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1, padding=1)\n",
    "        \n",
    "        # -- Build resnet logical layers\n",
    "        l = layers\n",
    "        \n",
    "        # logical layer1 - 3 bottleneck blocks with 64 filters and stride=1 \n",
    "        self.layer1 = self._make_layer(block, l[0].neck_ch, l[0].blocks, stride=l[0].stride)    # image is 16x16\n",
    "        \n",
    "        # logical layer2 - 4 bottleneck blocks with 128 filters and stride=2  (i.e. first halving)\n",
    "        self.layer2 = self._make_layer(block, l[1].neck_ch, l[1].blocks, stride=l[1].stride)    # image is 8x8\n",
    "        \n",
    "        # logical layer3 - 6 bottleneck blocks with 256 filters and stride=2  (i.e. second halving)\n",
    "        self.layer3 = self._make_layer(block, l[2].neck_ch, l[2].blocks, stride=l[2].stride)    # image is 4x4\n",
    "        \n",
    "        # logical layer4 - 3 bottleneck blocks with 512 filters and stride=2  (i.e. third halving)\n",
    "        self.layer4 = self._make_layer(block, l[3].neck_ch, l[3].blocks, stride=l[3].stride)    # image is 2x2\n",
    "        \n",
    "        # final ResNet layers - average pooling reduces size to 1x1 + fully connected layer of size 2048\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(int(512/DOWNSIZE_FACTOR) * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = list()\n",
    "        \n",
    "        # first Bottleneck block in the logical layer is the one that does the downsampling \n",
    "        layers.append(block(self.inplanes, planes, \n",
    "                            stride=stride, downsample=downsample,\n",
    "                            base_width=self.base_width, \n",
    "                            norm_layer=norm_layer))\n",
    "        \n",
    "        # the rest operate on the the downsampled result, keeping the size (i.e. using default stride of 1)\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                base_width=self.base_width,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFrYIsi1aUEm"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import model_urls\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, BLOCKS_50, pretrained, progress,\n",
    "                   **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_JHI42C-Xmh"
   },
   "source": [
    "### Definirea unui strat de normalizare de tip identitate\n",
    "Inputul este forwardat ca atare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCkBbX4H-Xmj"
   },
   "outputs": [],
   "source": [
    "class EmptyNorm(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(EmptyNorm, self).__init__()\n",
    "        self._modules = dict()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPex0rz3auId"
   },
   "source": [
    "## 3. Pregătirea pipeline-ului de antrenare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrizarea preprocesării datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoTsOIRQSPV0"
   },
   "outputs": [],
   "source": [
    "# First define the preprocessing ops for the train/test data\n",
    "crop_height = 32  # @param \n",
    "crop_width = 32  # @param\n",
    "NUM_CLASSES = 10  # @param\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "117ebPugarCO"
   },
   "source": [
    "### Initializarea modelului rețelei și funcții auxiliare pentru inspectarea modelului definit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfHEpqp3DZbR",
    "outputId": "8fec2fbc-2c64-427f-9e30-e4de49f81c25"
   },
   "outputs": [],
   "source": [
    "blocks = BLOCKS_50     # arhitectura blocurilor functionale\n",
    "\n",
    "net = None                       # type: nn.Module\n",
    "\n",
    "if flag_batch_norm == \"ON\":\n",
    "    net = resnet50(num_classes=NUM_CLASSES)\n",
    "else:\n",
    "    net = resnet50(num_classes=NUM_CLASSES, norm_layer=EmptyNorm)\n",
    "    \n",
    "net.train()                         # Default after init is train\n",
    "net = net.to(device)      # Move network to device\n",
    "\n",
    "print(list(net.modules())[0])\n",
    "\n",
    "# Let us test that we can propagate a batch through the defined networks\n",
    "select = 2\n",
    "inputs = batch_train_images.to(device)[:select]\n",
    "target = batch_train_labels[:select]\n",
    "\n",
    "output = net(inputs)\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "print(output)\n",
    "print(predicted)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-F4W5niV1sm"
   },
   "outputs": [],
   "source": [
    "# Get number of parameters in a model by iterating through the model parameters\n",
    "def get_num_params(model):\n",
    "    num_params = 0\n",
    "    for params in model.parameters():\n",
    "        num_params += params.shape.numel()\n",
    "        \n",
    "    return num_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7VKCh9ySddK",
    "outputId": "211916d9-252e-423b-ea96-806996b49071"
   },
   "outputs": [],
   "source": [
    "# Get number of parameters in the model. Verify that we have implemented models correctly\n",
    "print(\"Total number of parameters of models\")\n",
    "print(str(net.__class__), \": \", get_num_params(net))  \n",
    "\n",
    "# should be on the order of 23M for default ResNet\n",
    "# if scaled down by 4: 1.4M for ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXwpnrFWSmBg"
   },
   "outputs": [],
   "source": [
    "def top_k_accuracy(k, target, output):\n",
    "    batch_size = target.size(0)\n",
    "    \n",
    "    _, pred = output.topk(k, 1, True, True)\n",
    "    \n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.to(device).view(1, -1).expand_as(pred))\n",
    "\n",
    "    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "    correct_k.mul_(100.0 / batch_size)\n",
    "    \n",
    "    return correct_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrizarea optimizatorului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_dTKQblSzkm"
   },
   "outputs": [],
   "source": [
    "lr_init = 0.01                # initial learning rate\n",
    "lr_factor = 0.1             # learning rate decay factor\n",
    "weight_decay_factor = 1e-4  # weight decay factor for L2 weight regularization\n",
    "lr_schedule_milestones = [90e3, 100e3, 110e3]\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer - SGD with momentum and weight_decay for L2 weight regularization\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, weight_decay=weight_decay_factor)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "if flag_regularize:\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, weight_decay=weight_decay_factor)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=weight_decay_factor)\n",
    "        \n",
    "# Define learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_schedule_milestones, gamma=lr_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afișarea loss-ului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeHQMMqsS9Cz"
   },
   "outputs": [],
   "source": [
    "# Function that takes a list of losses and plots them.\n",
    "REFRESH_EVERY = 1000\n",
    "\n",
    "def plot_losses(loss_list, steps, ct):\n",
    "    if ct % REFRESH_EVERY == 0:\n",
    "        display.clear_output(wait=True)\n",
    "    \n",
    "    display.display(pl.gcf())\n",
    "    pl.plot(steps, loss_list, c='b')\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQBpZRP-TKI0"
   },
   "source": [
    "### Parametrizarea iterațiilor de antrenare, raportare și testare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNtIcyk7S_ub"
   },
   "outputs": [],
   "source": [
    "# Define number of training iterations and reporting intervals\n",
    "TRAIN_ITERS = 100e3  # @param\n",
    "REPORT_TRAIN_EVERY = 100  # @param\n",
    "PLOT_EVERY = 100  # @param\n",
    "REPORT_TEST_EVERY = 200  # @param\n",
    "TEST_ITERS = 100  # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ARGcbSGTFDN"
   },
   "source": [
    "## 4. Antrenarea modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSuV2dF-TDCD",
    "outputId": "845baf91-20b2-4a2f-927d-bd3d85d1b2d0"
   },
   "outputs": [],
   "source": [
    "# Question: What is the accuracy of the model at iteration 0, i.e. before training starts?\n",
    "\n",
    "EPOCHS = int(TRAIN_ITERS / (TRAIN_DATASET_SIZE / BATCH_SIZE_TRAIN))\n",
    "\n",
    "train_iter = 0\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "# simulate an inifinte test data provider by looping over the test data\n",
    "test_data_provider = loopy_test_loader(test_loader)\n",
    "\n",
    "# set model in train mode\n",
    "net.train()\n",
    "\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "ct = 0\n",
    "\n",
    "for epoch in range(int(EPOCHS)):  # loop over the dataset multiple times\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # set the learning rate and decay according to iteration schedule\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += top_k_accuracy(1, labels, outputs)\n",
    "        \n",
    "        if train_iter % REPORT_TRAIN_EVERY == REPORT_TRAIN_EVERY - 1:    # print every REPORT_TRAIN_EVERY mini-batch iterations\n",
    "            train_loss = running_loss / REPORT_TRAIN_EVERY\n",
    "            train_acc = running_acc / REPORT_TRAIN_EVERY\n",
    "            \n",
    "            print('[%d, %5d, %6d] LR: %.5f' % (epoch + 1, i + 1, train_iter, lr_scheduler.get_lr()[-1]))\n",
    "            print('[%d, %5d] loss: %.5f, acc: %.5f' %\n",
    "                  (epoch + 1, i + 1, train_loss, train_acc))\n",
    "            \n",
    "            losses.append(train_loss)\n",
    "            steps.append(train_iter)\n",
    "            \n",
    "            running_loss = 0\n",
    "            train_loss = 0\n",
    "            running_acc = 0\n",
    "            train_acc = 0\n",
    "            \n",
    "            \n",
    "        if train_iter % PLOT_EVERY == 0:\n",
    "            plot_losses(losses, steps, train_iter)\n",
    "            \n",
    "        train_iter += 1\n",
    "    \n",
    "        if train_iter % REPORT_TEST_EVERY == 0:\n",
    "            # set model in test mode\n",
    "            net.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # evaluate over at most TEST_ITER sub samples from the test_loader\n",
    "                test_iter = 0\n",
    "                test_loss = 0\n",
    "                correct = 0\n",
    "                \n",
    "                while test_iter < TEST_ITERS:\n",
    "                #for j, test_data in enumerate(test_loader, start=test_ct):\n",
    "                    test_data = next(test_data_provider)\n",
    "                        \n",
    "                    # get the test inputs; data is a list of [inputs, labels]\n",
    "                    test_inputs, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "                    \n",
    "                    out = net(test_inputs)\n",
    "                    test_loss += criterion(out, test_labels)\n",
    "                    \n",
    "                    correct += top_k_accuracy(1, test_labels, out)\n",
    "                    \n",
    "                    test_iter += 1\n",
    "                    \n",
    "                avg_test_loss = test_loss / TEST_ITERS\n",
    "                avg_acc = correct / TEST_ITERS\n",
    "                \n",
    "                print('[%d, %5d] avg_test_loss: %.5f, avg_test_acc: %.2f' \n",
    "                    % (epoch + 1, i + 1, avg_test_loss, avg_acc))\n",
    "                \n",
    "            # set model back in train mode\n",
    "            net.train()\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHOL_pDk-XnG"
   },
   "source": [
    "## 5. Interpretarea rezultatelor - TODO 3\n",
    "**Răspundeți la următoarele întrebări:**\n",
    "1. care este acuratețea obținută pentru un model cu DOWNSIZE_FACTOR = 4 și normalizare EmptyNorm? (atașați printscreen sau grafic)\n",
    "2. care este acuratețea obținută pentru un model cu DOWNSIZE_FACTOR = 1 și normalizare EmptyNorm? (atașați printscreen sau grafic)\n",
    "3. care este acuratețea obținută pentru un model cu DOWNSIZE_FACTOR = 4 și normalizare BatchNorm? (atașați printscreen sau grafic)\n",
    "4. care este acuratețea obținută pentru un model cu DOWNSIZE_FACTOR = 1 și normalizare BatchNorm? (atașați printscreen sau grafic)\n",
    "5. ce se întâmplă atunci când creșteți numărul de parametrii ai modelului?\n",
    "6. care este efectul utilizării normalizării de tip BatchNorm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKw4zNL--XnJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ComputerVisionPart1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
