{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tema 3 - Neural Style Transfer - Skel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/ML/homework/hw3/GM/Tema_3_Neural_Style_Transfer_Skel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX2vSwncklCs",
        "colab_type": "text"
      },
      "source": [
        "# Tema 3 - A new Picasso is in town\n",
        "## Neural Style Transfer\n",
        "### Autori: \n",
        "* George Muraru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtSEkgeUklFd",
        "colab_type": "text"
      },
      "source": [
        "## 1. Scopul temei\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8UBYxedmVGD",
        "colab_type": "text"
      },
      "source": [
        "Tema are ca scop folosirea rețelelor neurale convoluționale pentru a **modifica imagini prin preluarea stilului** de la o alta imagine.\n",
        "Este o tehnica prin care se genereaza o noua imaginie folosind o imagine de baza (eng. *content image*) și o imagine a cărui stil (eng. *style image*) dorim să îl transferăm la imaginea de bază (rezultat numit în temă *generated image*). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NLgkvzBs-88",
        "colab_type": "text"
      },
      "source": [
        "![result](https://raw.githubusercontent.com/cs-pub-ro/ML/master/homework/hw3/GM/img/colab/result.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWlglOAho87Q",
        "colab_type": "text"
      },
      "source": [
        "### 2. High Level Architecture\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1294/1*ZgW520SZr1QkGoFd3xqYMw.jpeg\" alt=\"High Level Architecture\" width=1250/>\n",
        "\n",
        "Reference: [Intuitive guide to neural style transfer](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDEJTiIl6s3v",
        "colab_type": "text"
      },
      "source": [
        "### Descărcare bibloteci/fișiere de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_dJm7DU8sec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install pillow\n",
        "\n",
        "!wget -q -O starry_night.jpg https://github.com/cs-pub-ro/ML/blob/master/homework/hw3/GM/img/style/starry_night.jpg?raw=true\n",
        "!wget -q -O cat.png https://github.com/cs-pub-ro/ML/blob/master/homework/hw3/GM/img/content/cat.png?raw=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59oEZKbhAm5Q",
        "colab_type": "text"
      },
      "source": [
        "### Biblioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqibAn_MAl7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx_5O9GDBAhX",
        "colab_type": "text"
      },
      "source": [
        "### Hiper-parametrii\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v4GUz4xBTgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = False #@param {type: \"boolean\"}\n",
        "ALPHA = 1 #@param {type: \"slider\", min: 0, max: 1e5, step: 1}\n",
        "BETA = 1e3 #@param {type: \"slider\", min: 0, max: 1e5, step: 1}\n",
        "IMG_SIZE = 512 #@param [128, 256, 512]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3bzS6VvnKte",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnvD1g-g8-yP",
        "colab_type": "text"
      },
      "source": [
        "Pentru a putea extrage **stilul** și **conținutul** unei imagini ne vom folosi de o rețea neurală deja antrenată.\n",
        "\n",
        "Noțiunea de a folosi o rețea pre-antrenată pentru a rezolva un alt task poartă denumirea de [Transfer Learning](https://ruder.io/transfer-learning/).\n",
        "\n",
        "Într-o rețea convoluțională primele layere extrag feature-uri low-level (acestea le vom folosi să extragem **stilul**), iar layerele \"mai apropiate de output\" ne vor furniza **conținutul**.\n",
        "\n",
        "Pentru acest lucru vom folosi o rețea VGGNet, mai specific VGG19.\n",
        "\n",
        "![VGG19](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means.jpg)\n",
        "\n",
        "Parametrii rețelei vor trebui să ramână fixați la valorile inițiale pe parcursul rulării. Din acest motiv va trebui să nu facem update parametrilor în timpul optimizării.\n",
        "\n",
        "Din rețeaua mai sus specificată vom folosi anumite layere (descrise mai jos) pentru a extrage feature-urile care ne interesează pentru cele 2 loss-uri."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "458-wVOb87Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO 1.0: Load model and move it to CUDA if selected\n",
        "\n",
        "# TODO 1.1: Freeze the parameters for the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOAffhL4HRUU",
        "colab_type": "text"
      },
      "source": [
        "### Imagini folosite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfOENh5Oq1iw",
        "colab_type": "text"
      },
      "source": [
        "Problema pe care dorim să o rezolvăm este de a genera **conținut** apropiat de o imagine de referință, conținut al cărui **stil** trebuie să fie apropiat de o altă imaginie.\n",
        "\n",
        "Pentru acest lucru ne vom defini 3 imagini:\n",
        "1. Imaginea a cărui conținut dorim să il copiem - notată $I_{C}$\n",
        "2. Imaginea a cărui stil dorim să îl copiem - notată $I_{S}$\n",
        "3. Imaginea generată (aceasta va avea inițial valori generate random) - notată $I_{G}$\n",
        "  * această imagine va fi modificată în timpul optimizării\n",
        "\n",
        "Intuitiv, soluția ar trebui să presupună rezolvarea a 2 probleme separate:\n",
        "* Generare de **conținut**\n",
        "* Generare de **stil**\n",
        "\n",
        "Pentru a cunatifica cât de aproape suntem de o soluție (o imaginie generată perfect) vom folosi 2 loss-uri, specificate în continuare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQppkQzZPoZO",
        "colab_type": "text"
      },
      "source": [
        "### Lucrul cu imagini\n",
        "\n",
        "Un prim pas care trebuie realizat este deschiderea și afișarea unei imagini.\n",
        "Ar trebui ca să avem 2 imagini descărcate: *starry_night.jpeg* și *cat.png*.\n",
        "\n",
        "De asemnea, deoarece folosim o rețea neurală predefinită, va trebui să modificăm inputul astfel încât acesta să corespundă inputului așteptat de către rețea.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4kBAGnBQdvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image(img_path):\n",
        "    \"\"\" Get an image ready to be run through the pretrained neural network\n",
        "\n",
        "    Args:\n",
        "        img_path (string): the path to the image\n",
        "\n",
        "    Returns:\n",
        "        A tensor with shape (B, H, W, C) where:\n",
        "        * B - represents the batch size (SHOULD BE 1)\n",
        "        * C - number of channels (3 - RGB)\n",
        "        * H - the height of the image (it should be IMG_SIZE after transformation)\n",
        "        * W - the width of the image (it should be IMG_SIZE after transformation)\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "    '''\n",
        "        TODO 1.0 - Use the transforms from torch library to do the following ops:\n",
        "        * Resize to an image of (IMG_SIZE, IMG_SIZE)\n",
        "        * Transform to a tensor (since the PIL library works with numpy arrays)\n",
        "        * The tensor should have values in the range [0, 1]\n",
        "        * Normalize using :\n",
        "            * mean = [0.485, 0.456, 0.406]\n",
        "            * std = [0.229, 0.224, 0.225]\n",
        "            (because the pretrained model was trained using those values)\n",
        "            (Formula: new_img = (img - mean) / std)\n",
        "    '''\n",
        "\n",
        "    # TODO 1.1: Add a size 1 dimension for the batch\n",
        "    # Hint: unsqueeze\n",
        "\n",
        "    # TODO 1.2: Move to cuda if support is enabled\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def show_imgs(*imgs):\n",
        "    \"\"\" Plot images received as parameters (on the same row with different\n",
        "        collumn)\n",
        "\n",
        "    Args:\n",
        "        imgs (tensors representing the images): images to plot\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    # TODO 2.0:\n",
        "    # Define the inverse of the `normalize` and `toTensor` operations performed\n",
        "    # in the `get_image` function\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "\n",
        "        # TODO 2.1: Detach, clone and move to CPU (the image)\n",
        "\n",
        "        # TODO 2.2: Remove the `batch` dimension (the first one)\n",
        "        # Hint: squeeze\n",
        "\n",
        "        # TODO 2.3: Apply the inverse of the `normalize` operation\n",
        "\n",
        "        plt.subplot(1, 2, i+1)\n",
        "\n",
        "        # Remove the x, y coordinates from the plot and show the image\n",
        "\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsFdy0gQQ7sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing Area\n",
        "img_cat = get_image(\"cat.png\")\n",
        "img_starry_night = get_image(\"starry_night.jpg\")\n",
        "\n",
        "assert isinstance(img_cat, torch.Tensor)\n",
        "assert img_cat.shape == (1, 3, IMG_SIZE, IMG_SIZE)\n",
        "assert not CUDA ^ img_cat.is_cuda\n",
        "\n",
        "show_imgs(img_cat, img_starry_night)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxsvH3J4klJy",
        "colab_type": "text"
      },
      "source": [
        "### Content Loss\n",
        "\n",
        "Loss-ul aceasta are rolul de a ne ajuta să recreăm **conținutul** unei imagini, el însemnând cât de mult diferă imaginea generată față de imaginea al cârui conținut dorim să îl \"copiem\".\n",
        "\n",
        "După cum s-a menționat mai sus, activările (eng. activation map/feature map) straturilor convoluționale aflate spre finalul rețelei ne oferă informații mai high-level despre o imagine.\n",
        "\n",
        "Putem folosi aceste activări pentru a calcula **content loss**:\n",
        "\n",
        "$$\n",
        "J_{content} = \\frac{1}{N}\\sum_{i,j}(a_{generated}^{i,j} - a_{content}^{i,j})^2\n",
        "$$\n",
        "\n",
        "Unde:\n",
        "* $N$ - numărul de elemente din feature map-ul specific\n",
        "* $a_{generate}$ - matricea activărilor specifice $I_{G}$\n",
        "* $a_{content}$ - matricea activărilor specifice $I_{C}$\n",
        "\n",
        "Pentru a obține feature map-ul se va face un **feedforward** cu imaginile:\n",
        "* $I_{G}$ pentru a obține $a_{generated}$\n",
        "* $I_{C}$ pentru a obține $a_{content}$\n",
        "\n",
        "Stratul de convoluție a carui activări ne interesează este **conv4_2** (vedeți imaginea de mai sus de la VGG19)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmi01F7l0X_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_feedforward(img, model):\n",
        "    ''' Do a feedforward step using the image given as parameter and keep track\n",
        "    of the activations\n",
        "\n",
        "    Args:\n",
        "        img (Tensor): the image used for feedforward\n",
        "        model (Model): the pretrained (and frozen) model\n",
        "\n",
        "    Returns:\n",
        "        A list containing the activations generated by passing the image through\n",
        "    the model\n",
        "    '''\n",
        "    activations = []\n",
        "    \n",
        "    # TODO 3.0: Compute the activations (for each layer of the model) and\n",
        "    # store them in the list\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "def get_content_loss(features_content, features_generated):\n",
        "    ''' Get the Content Loss\n",
        "\n",
        "    Args:\n",
        "        features_content ([Tensor]): the activations for I_C\n",
        "        features_generatd ([Tensor]): the activations for I_G\n",
        "    Returns:\n",
        "        loss (double) - the computed loss for the content\n",
        "    '''\n",
        "    # TODO 4.0: Compute the content lost\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlF2DEDvL5tO",
        "colab_type": "text"
      },
      "source": [
        "### Style Loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zLTGDSUjlPR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### **Gram Matrix (Style Matrix)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L11hp6Z4jtBi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Pentru a calcula *style loss-ul* va trebui să folosim *matricea Gram*, calculată pe activările anumitor straturi convoluționale.\n",
        "\n",
        "Matricea Gram a unui set de vectori V = $(v_0, v_1, v_2,...,v_n)$ este dată de produsul matriceal dintre $V și V^t$.\n",
        "\n",
        "Această matrice are rolul de a indica care set de feature-uri sunt corelate au valori mari împreună/sunt similare.\n",
        "\n",
        "Mai multe detalii puteți găsi [aici](https://arxiv.org/pdf/1606.01286.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3_Fee7jooV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### **Calcul Style Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x53eIjSNjyyr",
        "colab_type": "text"
      },
      "source": [
        "Style loss-ul va fi reprezentat de *distanța* între matricea gram specifică activărilor pentru imaginea $I_{G}$ și pentru imaginea $I_{S}$.\n",
        "\n",
        "Pentru activările unui specific layer convoluțional, formula de calcul este următoarea:\n",
        "$$\n",
        "    J_{style}^{l} = \\frac{1}{4N^2}\\sum_{i,j}(G^{i,j}(a_{generated}) - G^{i,j}(a_{style}))^2\n",
        "$$\n",
        "\n",
        "Unde:\n",
        "* l - layer-ul convoluțional pentru care se calculează loss-ul\n",
        "* $N$ - numărul de elemente din feature map-ul specific\n",
        "* $a_{generate}$ - matricea activărilor specifice $I_{G}$\n",
        "* $a_{style}$ - matricea activărilor specifice $I_{style}$\n",
        "\n",
        "Pentru a obține feature map-ul se va face un **feedforward** cu imaginile:\n",
        "* $I_{G}$ pentru a obține $a_{generated}$\n",
        "* $I_{S}$ pentru a obține $a_{style}$\n",
        "\n",
        "Deoarece activările pentru $I_{G}$ au fost deja calculate de la pasul de *Contnt Loss* acestea **nu vor mai fi recalulate la acest pas**.\n",
        "\n",
        "Dacă pentru calcularae *content loss-ului* am folosit un singur strat de convoluție, pentru a *captura* stilul unei imagini, vom folosi **mai multe straturi din rețeaua VGG19**, fiecare strat având o anumită pondere la *style loss-ul* final (vedeți cerința de mai jos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXKKD2q1YSYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gram_matrix(X):\n",
        "    ''' Compute the Gram Matrix for the tensor X (the activation map)\n",
        "    \n",
        "    Args:\n",
        "        X (Tensor): Tensor with shape (B, F, H, W)\n",
        "    \n",
        "    Returns:\n",
        "        Tensor representing the Gram Matrix\n",
        "    '''\n",
        "    g = None\n",
        "    _, c, h, w = X.shape\n",
        "\n",
        "    # TODO 5.0: `g` should be a matrix where:\n",
        "    # * the rows -- nr of channels\n",
        "    # * the columns -- elements for that specific channel\n",
        "    # X_new = ...\n",
        "    return g\n",
        "\n",
        "\n",
        "def get_style_loss(features_style, features_generated):\n",
        "    ''' Get the Style Loss\n",
        "\n",
        "    Args:\n",
        "        features_style ([Tensor]): the activations for I_S\n",
        "        features_generatd ([Tensor]): the activations for I_G\n",
        "    Returns:\n",
        "        loss (double) - the computed loss for the content\n",
        "    '''\n",
        "\n",
        "    # TODO 5.1 Compute style loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tproKf2Ng1D0",
        "colab_type": "text"
      },
      "source": [
        "### Generare imagine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahMNiGsZjivb",
        "colab_type": "text"
      },
      "source": [
        "Se vor folosi loss-urile definite anterior pentru a calcula un loss total și pentru a genera imaginea finală."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4w4zLdZyWpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_img = get_image(\"cat.png\")\n",
        "style_img = get_image(\"starry_night.jpg\")\n",
        "\n",
        "steps = 10000\n",
        "\n",
        "generated_img = content_img.clone()\n",
        "\n",
        "# Need to be set since this image will be updated using the optimizer\n",
        "generated_img.requires_grad = True\n",
        "\n",
        "# TODO 6.0: Get content and style features\n",
        "\n",
        "optimizer = optim.LBFGS([generated_img.requires_grad_()])\n",
        "\n",
        "it = [0]\n",
        "for i in range(1, steps+1):\n",
        "    def closure():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # TODO 6.1: Run feedforward for the generated_img\n",
        "\n",
        "            # TODO 6.2: Compute content loss\n",
        "\n",
        "            # TODO 6.3: Compute style loss\n",
        "\n",
        "            loss = ALPHA * content_loss + BETA * content_loss\n",
        "            loss.backward()\n",
        "\n",
        "            it[0] += 1\n",
        "            if it[0] % 500 == 0:\n",
        "                print(f'Style Loss: {style_loss} Content Loss: {content_loss}')\n",
        "                show_imgs(generated_img)\n",
        "\n",
        "            return loss\n",
        "\n",
        "    optimizer.step(closure)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yczjp7MMhYzw",
        "colab_type": "text"
      },
      "source": [
        "### Cerințe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQH8WQWckLu4",
        "colab_type": "text"
      },
      "source": [
        "1. [0.5pct] Încărcați modelul pre-antrenat VGG19, mutați-l pe CUDA (daca există suport) și faceți ca antrenarea să nu modifice parametrii modelului.\n",
        "\n",
        "2. [2pct] Scrieți codul necesar pentru a încarca o imagine și a o pregăti pentru a putea fi trimisă la rețeaua anterior încarcată.\n",
        "\n",
        "    Mutați datele pe CUDA (daca există suport).\n",
        "\n",
        "    Convertiți imaginea în formatul inițial pentru a putea fi afișată.\n",
        "\n",
        "\n",
        "3. [1pct] Implementați funcția *run_feedforward* care trebuie să facă o trecere a datelor prin rețea.\n",
        "\n",
        "4. [1pct] Calculați *Content Loss*.\n",
        "   \n",
        "   Folosiți layerul e convoluție: **conv4_2** pentru a extrage activarea necesară.\n",
        "\n",
        "4. [2pct] Calculați *Style Loss*.\n",
        "   \n",
        "   Folosiți layerele următoare pentru a extrage *style loss-ul*: **conv1_1, conv2_1, conv3_1, conv4_1, conv5_1**.\n",
        "\n",
        "    Fiecare strat va avea o pondere de 0.2.\n",
        "$$\n",
        "    J_{style} = \\sum_{i}w_i  J_{style}^{i}\n",
        "$$\n",
        "\n",
        "5. [2.5pct] Completați codul necesar pentru a genera imaginea finală.\n",
        "   \n",
        "   Vedeți ce se întâmplă când modificați parametrul ALPHA, BETA, learning rate-ul, ponderile de la *Style Loss* pentru fiecare strat, straturile folosite pentru extragerea *stilului* și a *conținutului*.\n",
        "\n",
        "    De asemenea, se poate experimenta și cu inițializarea $I_{G}$ cu valori random.\n",
        "\n",
        "6. [1pct] Rulați programul pentru alte 3-4 perechi de imagini.\n",
        "\n",
        "7. [Bonus - 2pct] Încercați să îmbunătățiți calitatea imaginii finale.\n",
        "\n",
        "    Posibile metode: adaugare loss adițional, calculat loss-urile folosind o altă formulă, schimbare rețea, etc.\n",
        "    Pentru aceasta trebuie să aveți în notebook o poză generată folosind metoda inițială și o altă poză cu noua metodă.\n",
        "\n",
        "**Atenție**: Este în regulă dacă pozele generate conțin artefacte! De asemenea, anumiți parametrii funcționeaza mai bine pentru diferite poze."
      ]
    }
  ]
}