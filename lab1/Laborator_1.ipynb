{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator 1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vwR9zMQRtihy",
        "q28omBa3Yp7W",
        "kVQscCaxXfvF",
        "3Q9tBSFJYt5D",
        "VgdP78g6rpvv"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7ZvN8Q8W0QCJ50ZRZSXES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab1/Laborator_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EUYXsI3JoDe",
        "colab_type": "text"
      },
      "source": [
        "# Învățare Automată\n",
        "# Grupare. Algoritmul K-Means\n",
        "### Autori:\n",
        "* Tudor Berariu - 2016\n",
        "* George Muraru - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9EKsaOzJ4Y6",
        "colab_type": "text"
      },
      "source": [
        "## 1. Scopul laboratorului\n",
        "Scopul laboratorului ı̂l reprezintă ı̂nțelegerea si implementarea unei metode de ı̂nvățarare nesupervizată pentru grupare (engl. clustering): **algoritmul K-Means**.\n",
        "\n",
        "Structura documentului este următoarea:\n",
        "* [Secțiunea 2](#scrollTo=lmsr8fvNKQ5m) prezintă contextul teoretic și formalizează problema ce se dorește rezolvată\n",
        "* [Secțiunea 3](#scrollTo=Aj8ThCuUKcEB) descrie algoritmul K-Means\n",
        "* [Secțiunea 4](#scrollTo=j5zthcYxMllG) enumeră câteva dintre limitările algoritmului K-Means și oferă câteva soluții simple pentru depășirea acestora\n",
        "* [Secțiunea 5](#scrollTo=yWjTUpn9OVY9) descrie câteva metode avansate pentru alegerea acestora.\n",
        "* [Secțiunea 6](#scrollTo=yWjTUpn9OVY9) descrie e metoda de evaluarea a performanței algoritmului\n",
        "* [Secțiunea 7](#scrollTo=dDFqbGHmDqtt) conține un setup inițial care trebuie rulat în colab (sau local) pentru instalarea dependențelor\n",
        "* [Secțiunea 8](#scrollTo=2xk677iNQRvQ) conține cerințele ce trebuie rezolvate ı̂n cadrul laboratorului\n",
        "* [Secțiunea 9](#scrollTo=muZzrV7uVxXv) conține o descriere a setului de date folosit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmsr8fvNKQ5m",
        "colab_type": "text"
      },
      "source": [
        "## 2. Problema\n",
        "Una dintre problemele fundamentale ale ı̂nvățării automate o reprezintă identificarea grupurilor (engl. clusters) ı̂ntr-un set de obiecte astfel ı̂ncât obiectele din același grup să prezinte un grad mare de similaritate. Această problemă de ı̂nvățare nesupervizată se numește cluster analysis.\n",
        "\n",
        "Problema grupării se poate formaliza ı̂n diferite feluri, existând mai multe abordări.\n",
        "În acest laborator vom rezolva problema grupării bazate pe **centroizi** (engl. centroid-based clustering).\n",
        "\n",
        "Se consideră un set de date $X = \\{x_{1} , . . . x_{N}\\}$ ce conține N exemple ı̂ntr-un spațiu D-dimensional. Scopul este partiționarea setului de date ı̂n K grupuri reprezentate prin K vectori prototip (engl. prototype vectors) $c_{k}$ (unde $k \\in \\{1,.,K\\}$) numiți centre sau centroizi (engl. centroids), astfel ı̂ncât distanța totală de la fiecare exemplu la cel mai apropiat centroid să fie minimă:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "J = \\sum_{i=1}^{N}\\sum_{k=1}^{K}in_{i,k} \\cdot \\left\\Vert{x_{i} - c_{k}}\\right\\Vert^2 \\tag{1}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "in_{i,k} = \n",
        "    \\begin{cases}\n",
        "    1, dacă\\ k = argmin\\left\\Vert{x_{i} - c_{l}}\\right\\Vert\\\\\n",
        "    0, altfel\n",
        "    \\end{cases} \\tag{2}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8ThCuUKcEB",
        "colab_type": "text"
      },
      "source": [
        "## 3. Algoritmul K-Means\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19y4eTM66qJmccoHE6zaRGOPPgkmwRRUu\" style=\"margin-left: 50;\" align=\"right\" width=\"350\" height=\"350\"/>\n",
        "\n",
        "Algoritmul K-Means [[1]](#M67) pornește de la un set de K centroizi aleși aleator din setul de obiecte. Se repetă alternativ următorii doi pași până când \n",
        "algoritmul converge:\n",
        "1. Se parcurg toate obiectele din setul de date și fiecare dintre acestea este alocat grupului corespunzator celui mai apropiat centroid\n",
        "2. Se recalculează centroidul fiecarui grup\n",
        "\n",
        "Algoritmul converge atunci când în urma unei iterații nu s-a modificat componența grupurilor.\n",
        "\n",
        "Pentru a înțelege de ce algoritmul K-Means găsește un minim al expresiei J (Formula 1), trebuie observat că cei doi pași optimizează succesiv parametrii $in_{i,k}$ și $c_{k}$. \n",
        "1. Fixând $c_{k}$, se recalculează $in_{i,k}$ conform ecuației 2.\n",
        "2. Fixând $in_{i,k}$, un minim al expresiei $J$ se găsește în punctul în care derivata este zero: \n",
        "$$\n",
        "\\begin{equation}\n",
        "\\sum_{i=1}^{N}in_{i,k}(x_{i} - c_{k}) = 0\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "![Alg K-Means](https://drive.google.com/uc?export=view&id=1V2m8cYakqLohh_mipzup-vzQlWHysGFE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zthcYxMllG",
        "colab_type": "text"
      },
      "source": [
        "## 4. Limitări ale algoritmului K-Means\n",
        "Algoritmul K-Means prezintă următoarele limitări importante:\n",
        "1. Numărul de grupuri K trebuie cunoscut a priori.\n",
        "  * Dacă acest număr nu este cunoscut, se poate rula algoritmul pentru diferite valori ale lui K și se poate alege o partiție convenabilă. Altfel, se poate alege o altă metodă de grupare.\n",
        "2. Algoritmul converge către un minim local.\n",
        "  * Nu există o metodă tractabilă care să garanteze un minim global. În practică\n",
        "se obișnuiește rularea algoritmului de mai multe ori și păstrarea celui mai bun\n",
        "rezultat.\n",
        "3. Rezultatul algoritmului depinde de alegerea centroizilor inițiali.\n",
        "  * Există mai multe strategii pentru alegerea centroizilor inițiai ($c_{k}, 1 \\le k \\le K$), două dintre acestea fiind descrie în [Secțiunea 5](#scrollTo=YB_3ayRlOOPP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB_3ayRlOOPP",
        "colab_type": "text"
      },
      "source": [
        "## 5. Alegerea centroizilor inițiali\n",
        "În algoritmul clasic K-Means cei K centroizi inițiali se aleg aleator din mulțimea obiectelor din setul de date. În continuare sunt descrise două metode mai bune pentru acest pas.\n",
        "\n",
        "### 5.1 Algoritmul K-Means++\n",
        "Algoritmul K-Means++ [[2]](#AV07) reprezintă o variantă ı̂mbunătățită a algoritmului K-Means ı̂n care centroizii inițiali sunt alesi după cum urmează\n",
        "* Primul centroid $c_{1}$ se alege aleator din setul de date\n",
        "* Următorii $K − 1$ se aleg succesiv dintre obiectele din setul de date cu o probabilitate\n",
        "$$\n",
        "\\begin{equation}\n",
        "p_i = \\frac{D(x_{i})^2}{\\sum_{x\\in{X}}D(x)^2}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "pentru fiecare obiect $x_{i}\\in{X}$, unde $D(x)$ este distanța cea mai mică dintre obiectul $x$ și un centroid deja ales.\n",
        "\n",
        "### 5.2 Metoda Kaufman\n",
        "În [[3]](#AV07) s-au testat pe diferite seturi de date mai multe metode de inițializare a centroizilor pentru algoritmul K-Means. Rezultatele au arătat că una dintre cele mai bune metode este cea propusă de Kaufman. Se alege întâi cel mai central obiect din setul de date, iar apoi se adaugă succesiv acele obiecte care strâng în jurul lor cel mai mare număr de elemente.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Oq7qVGywdonOBZhOZCFV-2aqHUE8Q71z\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWjTUpn9OVY9",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluarea unei grupări\n",
        "Nu există o rețetă unică pentru evaluarea unei grupări realizate pentru un set de date. În general, metricile țin cont de faptul că exemplele dintr-un grup trebuie să fie cât mai apropiate/similare, iar cele din grupuri diferite trebuie să fie cât mai diferite.\n",
        "Dacă sunt cunoscute clasele reale (precum ı̂ntr-o problemă de ı̂nvățare supervizată), atunci evaluarea se poate face mai ușor. Dintre metodele existente, este descrisă ı̂n continuare *Rand Index*.\n",
        "\n",
        "### 6.1 Rand Index\n",
        "Fiind date o grupare C și valorile reale T ale claselor din care fac parte obiectele dintr-un set de date, definim:\n",
        "* *TP (true positives)* numărul de perechi i, j care sunt ı̂n același grup ı̂n C și au aceeași clasă ı̂n T;\n",
        "* *FP (false positives)* numărul de perechi i, j care sunt ı̂n același grup ı̂n C, dar sunt ı̂n clase diferite ı̂n T ;\n",
        "* *FN (false negatives)* numărul de perechi i, j care sunt ı̂n grupuri diferite ı̂n C, dar au aceeași clasă ı̂n T ;\n",
        "* *TN (true negatives)* numărul de perechi i, j care sunt ı̂n grupuri diferite ı̂n C și au clase diferite ı̂n T.\n",
        "\n",
        "Metrica *Rand Index* este:\n",
        "$\n",
        "\\begin{equation}\n",
        "R = \\frac{TP + TN}{TP + FP + FN + TN} \\in [0, 1]\n",
        "\\end{equation}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFqbGHmDqtt",
        "colab_type": "text"
      },
      "source": [
        "## 7. Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwR9zMQRtihy",
        "colab_type": "text"
      },
      "source": [
        "### Dependențe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr7MO4rQtoqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q28omBa3Yp7W",
        "colab_type": "text"
      },
      "source": [
        "### Câteva biblioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK1fxRNOXteB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "from random import randint\n",
        "\n",
        "# Plotting stuff\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.markers\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVQscCaxXfvF",
        "colab_type": "text"
      },
      "source": [
        "### Parametrii necesari rulării\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEHiJQeYXjCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = 'Atom'  #@param ['Atom', 'Chainlink', 'EngyTime', 'GolfBall', 'Hepta', 'Lsun', 'Target', 'TwoDiamonds', 'WingNut']\n",
        "\n",
        "# Numărul de clustere\n",
        "K = 2  #@param {type: \"slider\", min: 2, max: 10}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9tBSFJYt5D",
        "colab_type": "text"
      },
      "source": [
        "### Funcții ajutătoare pentru descărcarea și lucrul cu setul de *date*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMvyyQnlYiIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getArchive():\n",
        "    \"\"\" Checks if FCPS.zip is present in the local directory, if not,\n",
        "    downloads it.\n",
        "\n",
        "    Returns:\n",
        "        A ZipFile object for the FCPS archive\n",
        "    \"\"\"\n",
        "\n",
        "    archive_url = (\"https://github.com/cs-pub-ro/ML/raw/master/lab1/FCPS.zip\")\n",
        "    local_archive = \"FCPS.zip\"\n",
        " \n",
        "    from os import path\n",
        "    if not path.isfile(local_archive):\n",
        "        import urllib\n",
        "        print(\"Downloading...\")\n",
        "        urllib.request.urlretrieve(archive_url, filename=local_archive)\n",
        "        assert(path.isfile(local_archive))\n",
        "        print(\"Got the archive\")\n",
        "\n",
        "    return ZipFile(local_archive)\n",
        "\n",
        "\n",
        "def getDataSet(archive, dataSetName):\n",
        "    \"\"\" Get a dataset from the FCPS.zip\n",
        "\n",
        "    Args:\n",
        "        archive (ZipFile): Object for the FCPS\n",
        "        dataSetName (String): The dataset name from the FCPS\n",
        "\n",
        "    Returns:\n",
        "        A tuple (Xs, labels)\n",
        "        Xs (numpy array): rows are the elements and the cols are the features\n",
        "        labels (numpy array): labels associated with Xs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    path = \"FCPS/01FCPSdata/\" + dataSetName\n",
        " \n",
        "    lrnFile = path + \".lrn\"\n",
        "    with archive.open(lrnFile, \"r\") as f:\n",
        "        N = int(f.readline().decode(\"UTF-8\").split()[1])\n",
        "        D = int(f.readline().decode(\"UTF-8\").split()[1])\n",
        "        f.readline()\n",
        "        f.readline()\n",
        "        Xs = np.zeros([N, D-1])\n",
        "        for i in range(N):\n",
        "            data = f.readline().decode(\"UTF-8\").strip().split(\"\\t\")\n",
        "            assert (len(data) == D)\n",
        "            assert (int(data[0]) == (i + 1))\n",
        "            Xs[i] = np.array(list(map(float, data[1:])))\n",
        "\n",
        "    clsFile = path + \".cls\"\n",
        "    with archive.open(clsFile, \"r\") as f:\n",
        "        labels = np.zeros(N).astype(\"uint\")\n",
        " \n",
        "        line = f.readline().decode(\"UTF-8\")\n",
        "        while line.startswith(\"%\"): \n",
        "            line = f.readline().decode(\"UTF-8\")\n",
        " \n",
        "        i = 0\n",
        "        while line and i < N:\n",
        "            data = line.strip().split(\"\\t\")\n",
        "            assert (len(data) == 2)\n",
        "            assert (int(data[0]) == (i + 1))\n",
        "            labels[i] = int(data[1])\n",
        "            line = f.readline().decode(\"UTF-8\")\n",
        "            i = i + 1\n",
        " \n",
        "        assert (i == N)\n",
        " \n",
        "    return Xs, labels\n",
        "\n",
        "\n",
        "def plotClusters(Xs, labels, centroids, clusters):\n",
        "    \"\"\" Plot the data with the true labels alongside the centroids and the\n",
        "    predicted cluster.\n",
        "    If the elements from the dataset are not 2 or 3 dimensional then print\n",
        "    the index, predicted cluster and true label.\n",
        "\n",
        "    Args:\n",
        "        Xs (numpy array): dataset\n",
        "        labels (numpy array): real/true labels\n",
        "        centroids (numpy array): positions for the centroids\n",
        "        clusters (numpy array): predicted labels\n",
        "    \"\"\"\n",
        "\n",
        "    labelsNo = np.max(labels)\n",
        "    K = centroids.shape[0]\n",
        "\n",
        "    markers = []\n",
        "\n",
        "    while len(markers) < labelsNo:\n",
        "        markers.extend(list(matplotlib.markers.MarkerStyle.filled_markers))\n",
        "\n",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, K+1))\n",
        "    if Xs.shape[1] == 2:\n",
        "        x = Xs[:,0]\n",
        "        y = Xs[:,1]\n",
        "        for (_x, _y, _c, _l) in zip(x, y, clusters, labels):\n",
        "            plt.scatter(_x, _y, s=500, c=[colors[_c]], marker=markers[_l])\n",
        "        plt.scatter(centroids[:,0], centroids[:, 1],\n",
        "                    s=800, c=[colors[K]], marker=markers[labelsNo])\n",
        "        plt.show()\n",
        "    elif Xs.shape[1] == 3:\n",
        "        x = Xs[:,0]\n",
        "        y = Xs[:,1]\n",
        "        z = Xs[:,2]\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        for (_x, _y, _z, _c, _l) in zip(x, y, z, clusters, labels):\n",
        "            ax.scatter(_x, _y, _z, s=200, c=[colors[_c]], marker=markers[_l])\n",
        "        ax.scatter(centroids[:,0], centroids[:, 1], centroids[:, 2],\n",
        "                    s=400, c=[colors[K]], marker=markers[labelsNo])\n",
        "        plt.show()\n",
        "    else:\n",
        "        for i in range(Xs.shape[0]):\n",
        "            print(f\"{i} : {clusters[i]} ~ {labels[i]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdP78g6rpvv",
        "colab_type": "text"
      },
      "source": [
        "### Încărcare set de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSpZu4WhroqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xs, labels = getDataSet(getArchive(), DATASET_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xk677iNQRvQ",
        "colab_type": "text"
      },
      "source": [
        "## 8. Cerințe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYI7jZaxkT34",
        "colab_type": "text"
      },
      "source": [
        "1. [6 pct] Implementați algoritmul K-Means descris în [Secțiunea 3](#scrollTo=Aj8ThCuUKcEB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmGzukavXg4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def kMeans(K, Xs):\n",
        "    (N, D) = Xs.shape\n",
        " \n",
        "    centroids = np.zeros((K, D))\n",
        "    clusters = np.zeros(N).astype(\"uint\")\n",
        "\n",
        "    # TODO: Cerința 1\n",
        "    \n",
        "    return clusters, centroids\n",
        "\n",
        "clusters, centroids = kMeans(K, Xs)\n",
        "plotClusters(Xs, labels, centroids, clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwf36n5zXN17",
        "colab_type": "text"
      },
      "source": [
        "2. [2 pct] Implementați metrica *Rand Index* descrisă în [Secțiunea 6.1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLfCL-dAAyf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randIndex(clusters, labels):\n",
        "    \n",
        "    # TODO: Cerința 2\n",
        "\n",
        "    return 0.5\n",
        "\n",
        "print(\"randIndex:\", randIndex(clusters, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enL8W9AdAub_",
        "colab_type": "text"
      },
      "source": [
        "3. [2 pct] Testați algoritmul implementat și eficiența acestuia pe seturile de date din arhivă. Puteți selecta alt set de date folosind *DATASET* din [Parametrii necesari rulării](#scrollTo=kVQscCaxXfvF).\n",
        "    \n",
        "    **Explicați de ce** pe unele seturi de date rezultatele sunt *nesatisfăcătoare*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj3dmiZ5W4ec",
        "colab_type": "text"
      },
      "source": [
        "4. [2 pct] Implementați unul dintre cei doi algoritmi prezentați ı̂n Secțiunea 5:\n",
        "  * metoda Kaufman pentru alegerea centroizilor inițiali\n",
        "  * algoritmul K-Means++\n",
        "\n",
        "    Comparați grupările obținute astfel cu cele obținute cu algoritmul K-Means.\n",
        "\n",
        "    Este utilă inițializarea atentă a centroizilor?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMdEknFmXL6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muZzrV7uVxXv",
        "colab_type": "text"
      },
      "source": [
        "## 9. Set de Date\n",
        "În cadrul acestui laborator veți folosi seturile de date [FCPS](https://github.com/cs-pub-ro/ML/raw/master/lab1/FCPS.zip) (Fundamental Clustering\n",
        "Problem Suite) ale Philipps Universität Marburg.\n",
        "\n",
        "Pentru fiecare set de date veți găsi următoarele fișiere ı̂n subdirectorul 01FCPSdata:\n",
        "* $<$nume$>$.lrn - setul de date cu un id pentru fiecare obiect,\n",
        "* $<$nume$>$.cls - clasele reale ale obiectelor.\n",
        "Coloanele sunt separate prin TAB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtkW7x139Us6",
        "colab_type": "text"
      },
      "source": [
        "# Bibliografie\n",
        "<a name=\"M67\">[1] *James MacQueen et al. Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1, pages 281–297. California, USA, 1967*</a>\n",
        "\n",
        "<a name=\"AV07\">[2] *David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027–1035. Society for Industrial and Applied Mathematics, 2007*</a>\n",
        "\n",
        "<a name=\"PLL99\">[3] *José Manuel Pena, Jose Antonio Lozano, and Pedro Larranaga. An empirical comparison of four initialization methods for the K-Means algorithm. Pattern recognition letters, 20(10):1027–1040, 1999*</a>\n"
      ]
    }
  ]
}